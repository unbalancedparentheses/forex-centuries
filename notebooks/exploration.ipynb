{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forex-centuries: Interactive Exploration\n",
    "\n",
    "This notebook walks through every major dataset in the forex-centuries project.\n",
    "Run `python build.py` first to generate the derived data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nfrom pathlib import Path\n\n# Allow imports from project root\nROOT = Path.cwd().parent\nsys.path.insert(0, str(ROOT))\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.stats import probplot, kurtosis\n\nSOURCES = ROOT / \"data\" / \"sources\"\nDERIVED = ROOT / \"data\" / \"derived\"\nANALYSIS = DERIVED / \"analysis\"\nNORM = DERIVED / \"normalized\"\n\nif not NORM.exists() or not ANALYSIS.exists():\n    raise FileNotFoundError(\"Derived data not found. Run 'python build.py' first.\")\n\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (12, 5)\nplt.rcParams[\"figure.dpi\"] = 100"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Yearly Panel (243 countries, 1500-2025)\n",
    "\n",
    "The unified panel merges MeasuringWorth, Clio Infra, and the Global Macro Database\n",
    "with priority MW > CI > GMD for overlapping (year, country) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = pd.read_csv(NORM / \"yearly_unified_panel.csv\")\n",
    "print(f\"Shape: {panel.shape}\")\n",
    "print(f\"Countries: {panel['country'].nunique()}\")\n",
    "print(f\"Year range: {panel['year'].min()}-{panel['year'].max()}\")\n",
    "print(f\"\\nSource breakdown:\")\n",
    "print(panel[\"source\"].value_counts())\n",
    "\n",
    "# Longest series\n",
    "series_len = panel.groupby(\"country\").size().sort_values(ascending=False)\n",
    "print(f\"\\nLongest series:\")\n",
    "for country, n in series_len.head(5).items():\n",
    "    sub = panel[panel[\"country\"] == country]\n",
    "    print(f\"  {country}: {n} years ({sub['year'].min()}-{sub['year'].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "for country, color in [(\"United Kingdom\", \"#DD8452\"), (\"Japan\", \"#55A868\"), (\"Switzerland\", \"#C44E52\")]:\n",
    "    sub = panel[panel[\"country\"] == country].sort_values(\"year\")\n",
    "    ax.plot(sub[\"year\"], sub[\"rate_per_usd\"], label=country, color=color)\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Rate per USD\")\n",
    "ax.set_title(\"Selected currencies vs USD (yearly)\")\n",
    "ax.legend()\n",
    "ax.set_yscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Daily Data (23 currencies, 1971-2025)\n",
    "\n",
    "FRED H.10 release: 23 daily currency pairs normalized to foreign-per-USD convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = pd.read_csv(NORM / \"fred_daily_normalized.csv\")\n",
    "print(f\"Shape: {daily.shape}\")\n",
    "print(f\"Currencies: {sorted(daily['currency'].unique())}\")\n",
    "print(f\"Date range: {daily['date'].min()} to {daily['date'].max()}\")\n",
    "\n",
    "# Basic stats\n",
    "stats = pd.read_csv(ANALYSIS / \"daily_volatility_stats.csv\")\n",
    "print(f\"\\nVolatility stats (top 5 by kurtosis):\")\n",
    "print(stats[[\"currency\", \"annualized_volatility\", \"excess_kurtosis\", \"tail_ratio\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise correlation sample\n",
    "corr = pd.read_csv(ANALYSIS / \"daily_correlation_matrix.csv\", index_col=0)\n",
    "sample = [\"EUR\", \"GBP\", \"JPY\", \"CHF\", \"BRL\", \"CNY\"]\n",
    "sample = [c for c in sample if c in corr.columns]\n",
    "print(\"Daily log-return correlations (sample):\")\n",
    "print(corr.loc[sample, sample].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fat Tails\n",
    "\n",
    "Every currency pair shows heavier tails than Gaussian. Here we inspect EUR/USD\n",
    "with a histogram and QQ-plot, then compare kurtosis across all currencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.read_csv(ANALYSIS / \"daily_log_returns.csv\")\n",
    "eur = returns[returns[\"currency\"] == \"EUR\"][\"log_return\"].values\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1.hist(eur, bins=200, density=True, alpha=0.7, color=\"#4C72B0\", label=\"Observed\")\n",
    "from scipy.stats import norm\n",
    "mu, sigma = eur.mean(), eur.std()\n",
    "x = np.linspace(-0.05, 0.05, 500)\n",
    "ax1.plot(x, norm.pdf(x, mu, sigma), \"r-\", lw=2, label=\"Normal fit\")\n",
    "ax1.set_xlim(-0.05, 0.05)\n",
    "ax1.set_xlabel(\"Daily log return\")\n",
    "ax1.set_ylabel(\"Density\")\n",
    "ax1.set_title(\"EUR/USD: observed vs Gaussian\")\n",
    "ax1.legend()\n",
    "\n",
    "# QQ-plot\n",
    "(osm, osr), (slope, intercept, _) = probplot(eur, dist=\"norm\")\n",
    "ax2.scatter(osm, osr, s=3, alpha=0.5, color=\"#4C72B0\")\n",
    "xlim = ax2.get_xlim()\n",
    "x_ref = np.linspace(xlim[0], xlim[1], 100)\n",
    "ax2.plot(x_ref, slope * x_ref + intercept, \"r-\", lw=1.5)\n",
    "ax2.set_xlabel(\"Theoretical quantiles\")\n",
    "ax2.set_ylabel(\"Observed quantiles\")\n",
    "ax2.set_title(\"EUR/USD: QQ-plot\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurtosis comparison across all currencies\n",
    "kurt_data = []\n",
    "for currency, grp in returns.groupby(\"currency\"):\n",
    "    r = grp[\"log_return\"].values\n",
    "    kurt_data.append({\"currency\": currency, \"excess_kurtosis\": kurtosis(r, fisher=True)})\n",
    "kurt_df = pd.DataFrame(kurt_data).sort_values(\"excess_kurtosis\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.barh(kurt_df[\"currency\"], kurt_df[\"excess_kurtosis\"], color=\"#4C72B0\")\n",
    "ax.set_xlabel(\"Excess kurtosis\")\n",
    "ax.set_title(\"Fat tails: excess kurtosis by currency (daily log returns)\")\n",
    "ax.set_xscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regime Analysis\n",
    "\n",
    "The Ilzetzki-Reinhart-Rogoff classification assigns each country-year a regime type\n",
    "(peg, crawling peg, managed float, free float, freely falling, dual market)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regimes = pd.read_csv(ANALYSIS / \"yearly_regime_classification.csv\")\n",
    "print(f\"Regime data: {len(regimes):,} country-year obs, {regimes['country'].nunique()} countries\")\n",
    "print(f\"\\nRegime distribution:\")\n",
    "print(regimes[\"regime_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of regime distribution\n",
    "counts = regimes[\"regime_label\"].value_counts()\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(counts.index, counts.values, color=\"#4C72B0\")\n",
    "ax.set_ylabel(\"Country-year observations\")\n",
    "ax.set_title(\"Exchange rate regime distribution (1940-2019)\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility by regime\n",
    "cond_stats = pd.read_csv(ANALYSIS / \"regime_conditional_stats.csv\")\n",
    "print(\"Regime-conditional statistics:\")\n",
    "print(cond_stats[[\"regime\", \"n_observations\", \"volatility\", \"excess_kurtosis\"]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gold Inflation\n",
    "\n",
    "Gold purchasing power shows the long-run debasement of fiat currencies.\n",
    "Cumulative retained percentage tells how much purchasing power a currency\n",
    "has kept relative to its starting year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = pd.read_csv(ANALYSIS / \"yearly_gold_inflation.csv\")\n",
    "print(f\"Gold inflation data: {len(gold):,} rows, {gold['country'].nunique()} countries\")\n",
    "print(f\"Year range: {gold['year'].min()}-{gold['year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative debasement for selected currencies\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "for country, color, label in [\n",
    "    (\"United States\", \"#4C72B0\", \"USD\"),\n",
    "    (\"United Kingdom\", \"#DD8452\", \"GBP\"),\n",
    "    (\"Japan\", \"#55A868\", \"JPY\"),\n",
    "    (\"Switzerland\", \"#C44E52\", \"CHF\"),\n",
    "]:\n",
    "    sub = gold[gold[\"country\"] == country].sort_values(\"year\")\n",
    "    if len(sub) > 0:\n",
    "        ax.plot(sub[\"year\"], sub[\"cumulative_retained_pct\"],\n",
    "                label=f\"{label} (since {int(sub['base_year'].iloc[0])})\",\n",
    "                color=color, linewidth=1.2)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"% gold purchasing power retained (log)\")\n",
    "ax.set_title(\"Currency debasement against gold\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Medieval Data\n",
    "\n",
    "The MEMDB Spufford dataset contains 13,197 exchange quotations from 1106-1500,\n",
    "covering 521 places across Europe, Byzantium, the Levant, and North Africa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spufford = pd.read_csv(SOURCES / \"memdb\" / \"memdb_spufford_medieval_exchange_rates.csv\")\n",
    "print(f\"Spufford: {len(spufford):,} records\")\n",
    "print(f\"Columns: {list(spufford.columns)}\")\n",
    "print(f\"\\nOldest records:\")\n",
    "print(spufford.sort_values(\"year\").head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading cities by record count\n",
    "if \"place\" in spufford.columns:\n",
    "    col = \"place\"\n",
    "elif \"from_place\" in spufford.columns:\n",
    "    col = \"from_place\"\n",
    "else:\n",
    "    col = spufford.columns[1]  # fallback\n",
    "\n",
    "top_places = spufford[col].value_counts().head(20)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.barh(top_places.index[::-1], top_places.values[::-1], color=\"#4C72B0\")\n",
    "ax.set_xlabel(\"Number of exchange quotations\")\n",
    "ax.set_title(\"Top 20 medieval trading cities by exchange records\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}